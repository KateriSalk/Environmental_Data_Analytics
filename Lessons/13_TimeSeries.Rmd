
---
title: "13: Time Series Analysis"
author: "Environmental Data Analytics | Kateri Salk"
date: "Spring 2019"
output: pdf_document
geometry: margin=2.54cm
editor_options: 
  chunk_output_type: console
---

## LESSON OBJECTIVES
1. Describe the aspects of hierarchical models, fixed effects, and random effects
2. Choose and justify appropriate statistical models when time is an explanatory variable
3. Apply repeated measures ANOVA to datasets with temporal components

## SET UP YOUR DATA ANALYSIS SESSION

```{r, message = FALSE, warning = FALSE}
getwd()
library(tidyverse)
#install.packages("lubridate")
library(lubridate)
#install.packages("nlme")
library(nlme)
#install.packages("lsmeans")
library(lsmeans)
#install.packages("multcompView")
library(multcompView)

PeterPaul.chem <- read.csv("./Data/Processed/NTL-LTER_Lake_ChemistryPhysics_PeterPaul_Processed.csv")

# Set date to date format
PeterPaul.chem$sampledate <- as.Date(PeterPaul.chem$sampledate, 
                                               format = "%m/%d/%y")

mytheme <- theme_classic(base_size = 14) +
  theme(axis.text = element_text(color = "black"), 
        legend.position = "top")
theme_set(mytheme)

```

## HIERARCHICAL MODELS

**Hierarchical models,** or **mixed-effects models,** are a type of linear model in which explanatory variables are given a model whose parameters are also estimated by the data. The coefficients associated with explanatory variables thus may not be a single value but instead be sampled from a distribution, called the hyper-distribution, which is defined by the modeler. The advantage of the hierarchical model is that it builds capacity to describe multiple layers of stochasticity, which enables accounting of all aspects of uncertainty in a system. Specifically, we can separately model the process of interest and the sampling process. 

The coefficients of a hierarchical model are divided into two categories: **fixed effects** and **random effects.** A **fixed effect** is a factor whose levels are experimentally determined or whose interest lies in the effects of each level (e.g., covariates, treatments, interactions). A **random effect** is a factor whose levels are sampled from a larger population, or whose interest lies in the variation among them rather than the specific effect of each level. In choosing whether you are dealing with a fixed or a random effect, consider the following questions: 

  + Do you have a particular interest in the studied factor level?

  + Have you included all possible levels in the study?
  
  + Do you have interest in the variance among levels?
  
  + Do you have interest in generalizing to factor levels that you did not study?
  
One common variable in hierarchical models is **time.** Time can be a complicated explanatory variable, as it can act as either a fixed or a random effect depending on the study design and research question. Due to **temporal autocorrelation,** conditions measured at a single site will be highly influenced by the conditions preceding the sampling date. Therefore, two samples taken in relatively close temporal proximity may not necessarily be independent of one another. Treating time as a random effect will account for temporal trends in observations (e.g., diel or seasonal patterns) that may not be of interest for your study.

Another common variable in hierarchical models is **space.** In many situations, we may want to infer conditions beyond the sites that we have sampled. By treating space as a random variable, we may be able to extrapolate conditions of the response variable across a spatial gradient.

## REPEATED MEASUREMENTS AND AUTOCORRELATION

In many situations where monitoring is conducted, samples taken repeatedly at a given site may not be considered truly independent. The conditions present on a given day may be dependent on conditions present earlier in time. This is clearly an issue for the way we might traditionally think of experimental design and statistical independence, but this type of study design is often of interest in the field of environmental science. We can set up models to consider autocorrelation of time within a given place. One example of this type of model is a **repeated measures ANOVA**.

Let's think about the situation of temperature monitoring in the NTL-LTER lake sites, Peter and Paul Lakes. We might be interested to know whether surface temperatures in the summer have increased over time in response to climate change. However, we know that (a) temperature conditions on a given date are dependent on conditions earlier in the season, and (b) there is considerable variability across the summer season within a year (i.e., cooler temperatures occurring in June vs. August). We can set up a hierarchical model to deal with the autocorrelation by date as well as the variability associated with seasonality.

Let's wrangle our data and visualize a preliminary relationship between our variables of interest.
```{r}
PeterPaul.summertemp <- 
  PeterPaul.chem %>%
  select(lakename:temperature_C) %>%
  #filter for Julian days in June-August and surface measurements
  filter(daynum > 151 & daynum < 243 & depth == 0 ) %>%
  #add a "week" column to represent seasonality
  mutate(Week = week(sampledate)) %>%
  #code won't work(further down) if there are NAs
  na.exclude()

ggplot(PeterPaul.summertemp, aes(x = sampledate, y = temperature_C, color = lakename)) +
  geom_point() +
  scale_color_manual(values = c("#7fcdbb", "#253494"))
```

We know temperature on a singles day depends on the day before in the season.
Next, we will determine the degree of temporal autocorrelation in our dataset. We will use the package `nlme` for our analyses. Another good package for running hierarchical, or mixed-effects, models is `lme4`. For the basic types of hierarchical models, these packages have about the same functionality.

```{r}
# Determine autocorrelation in residuals
TempTest.auto <- lme(data = PeterPaul.summertemp,
                     temperature_C ~ sampledate * lakename, #response variable: temperature, predicing variables: sample date and lakename; this is a fixed effect coavoa model
                     random = ~1|Week) #this is our random effect, 1 means each week has an intercept in the function
TempTest.auto

ACF(TempTest.auto)

```

Random effects:
 Formula: ~1 | Week
        (Intercept) Residual
StdDev:    1.588171 1.941958

we are interested in variability instead of the intercept (this is for fixed effects)

1.58 standard deviation is the variability in temperature across the season


This model structure should look familiar, with a typical linear model structure and dataframe defined. The addition here is that we have defined Week as a random variable. Essentially, we are interested not in the specific effects of each week but in the variability among weeks, so we have defined it as a random effect (essentially coming from a larger distribution of seasonal variability). The ~1 statement indicates that each week has its own intercept in the model. From here, we want to take the first order correlation to specify our autocorrelation structure. From the ACF output, we take the 2nd value (the innermost group level) to define the degree of autocorrelation. This number will always fall between 0 and 1. Notice that there is a fairly large degree of autocorrelation in our variables.

We will now create a repeated measures ANOVA model now that we have defined our autocorrelation structure. The way we have set up this model, we are considering temporal autocorrelation within the levels of Week, and we have retained Week as a random effect. 

The correlation statement in the model is defined as follows: `correlation = structure(form = ~ time | subjvar)`, where structure is the autocorrelative structure (options in `?corClasses`), time is the temporal variable, and subjvar is the variable for experimental units.

```{r, warning = FALSE}
TempTest.mixed <- lme(data = PeterPaul.summertemp,
                     temperature_C ~ sampledate * lakename, 
                     random = ~1|Week,
                     #specify autocorrelation structure of order 1
                     #sampledate is duplicated in some cases, so need to split up by lake
                     correlation = corAR1(form = ~ sampledate/lakename|Week, value = 0.423), #R doesn't like when it's on the same date, so we specify by lake name
                     #define method as restricted maximum likelihood
                     method = "REML")
summary(TempTest.mixed)

# Random effects:
#  Formula: ~1 | Week
#         (Intercept) Residual
# StdDev:    1.618912 1.930645
# there is a standard deviation of 1.61 degree celcius across the season

#                                   Value Std.Error  DF  t-value p-value
# (Intercept)                   20.466650 0.5323160 846 38.44831  0.0000
# sampledate                     0.000099 0.0000266 846  3.73751  0.0002
# lakenamePeter Lake             0.072415 0.4409492 846  0.16423  0.8696
# sampledate:lakenamePeter Lake  0.000005 0.0000379 846  0.12217  0.9028
# the 20.46 degree is paul lake on the first date of sampling
# 0.000099*365*32 = 1.16 degree increase from 1984 to 2016
# not much difference between two lakes p = 0.87
# no interaction between date and lake p=0.9


# Compare the random effects model with the fixed effects model
TempTest.fixed <- gls(data = PeterPaul.summertemp,
                      temperature_C ~ sampledate * lakename, 
                      method = "REML")
summary(TempTest.fixed)

# Coefficients:
#                                   Value Std.Error  t-value p-value
# (Intercept)                   20.800214 0.3770183 55.17031  0.0000
# sampledate                     0.000085 0.0000326  2.59341  0.0097
# lakenamePeter Lake             0.085356 0.5344819  0.15970  0.8732
# sampledate:lakenamePeter Lake  0.000006 0.0000463  0.12712  0.8989

# why bother doing the random effect model if the fixed effect model generate a similar coefficients?
# 0.000085*365*32 = 0.99, this doesn't reach 1 degree, this could have a significant implication for the ecology decision

anova(TempTest.mixed, TempTest.fixed)
# The lower the AIC, the better.
# The p-value tells us whether those models have a significantly different fit

#                 Model df      AIC      BIC    logLik   Test  L.Ratio p-value
# TempTest.mixed     1  7 3678.638 3711.928 -1832.319                        
# TempTest.fixed     2  5 4019.694 4043.473 -2004.847 1 vs 2 345.0563  <.0001
# This means that there is a significant difference in the output run by mixted model and the fixed model; and a lower AIC, which is the mixed model, indicates it did a better job in capturing the variability


# Post-hoc test
# This will yield groupings of temperature by lake for the average date value
TempTest.posthoc = lsmeans(TempTest.mixed, ~ sampledate * lakename)
cld(TempTest.posthoc, alpha = 0.05, Letters = letters, adjust = "tukey")

 # sampledate lakename   lsmean    SE df lower.CL upper.CL .group
 #      10989 Paul Lake    21.6 0.443 13     20.4     22.7  a    
 #      10989 Peter Lake   21.7 0.443 13     20.6     22.8  a
 # This means that two lakes' temperature has a nice overlap, there is not many difference in their temperature

# display our final relationship
ggplot(PeterPaul.summertemp, aes(x = sampledate, y = temperature_C, color = lakename)) +
  geom_point() +
  scale_color_manual(values = c("#7fcdbb", "#253494")) +
  geom_abline(intercept = 20.47, slope = 0.0001)
```

Question: How would you interpret the collective results of your mixed effects model in the context of the study question?

> ANSWER: 
